import math
from gameState import GameState
from debugServer import DebugServer
import pathfinding

class RLLearn_SARAS():
    def __init__(self, addr, port):
        # self.subscriptions = [MsgType.LIGHT_STATE]
        # super().__init__(addr, port, message_buffers, MsgType, FREQUENCY, self.subscriptions)
        # self.state = None
        # self.grid = copy.deepcopy(grid)

        # self.policy = np.zeros((grid.shape, 4))
        # self.lr = 0.01
        # self.min_lr = 0.001
        # self.lr_decay = 0.99
        # self.gamma = 1
        # self.eps = 0.1
        # self.eps_decay = 0.999
        # self.min_eps = 0.001
        return

    def stepping():
        #Updating the new state, the reward for the step, whether pacman is done or not
        return
    
    def get_action_random():
        return
        
    def get_action_greedy():
        return
        
    def get_action_epsilon():
        return
    
    def calculate_reward(state1, state2, action):
        return 0
    
    def action_to_command():
        return
    
    def train():
        return


    def evaluate():
        return

    